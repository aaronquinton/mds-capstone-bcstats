{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Sensitive Comments\n",
    "\n",
    "The following notebook outlines the procedure for removing the sensitive information. The finalized script is in the src directory.\n",
    "\n",
    "Using the python module `spacy` we are able to perform named entity recognition (NER) on all of the comments. This tags a variety of labels on words or ngrams in each comment. We are interested in the text that has been tagged `PERSON` which could potentially reveal sensitive information. In theory, NER should have identified any possible names, however there is a possibility that it missed some. This is the case if someone used a persons name but all in lower case letters. Manually looking at a sample of the data we saw no instances of this or other cases where spacy was unable to identify a persons name being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Qualitative Data\n",
    "df_raw = pd.read_excel(\"../data/raw/2018 WES Qual Coded - Final Comments and Codes.xlsx\",\n",
    "                       skiprows = 1)\n",
    "comments = df_raw[\"2018 Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy's library and apply NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = [nlp(comment) for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>documents</th>\n",
       "      <th>person_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The problem with the BCSS is Linda Cavanaugh a...</td>\n",
       "      <td>Linda Cavanaugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The problem with the BCSS is Linda Cavanaugh a...</td>\n",
       "      <td>Sheriffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The problem with the BCSS is Linda Cavanaugh a...</td>\n",
       "      <td>JIBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>The problem with the BCSS is Linda Cavanaugh a...</td>\n",
       "      <td>JIBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Administration people should have better oppor...</td>\n",
       "      <td>Admin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                                          documents  \\\n",
       "0               2  The problem with the BCSS is Linda Cavanaugh a...   \n",
       "1               2  The problem with the BCSS is Linda Cavanaugh a...   \n",
       "2               2  The problem with the BCSS is Linda Cavanaugh a...   \n",
       "3               2  The problem with the BCSS is Linda Cavanaugh a...   \n",
       "4               6  Administration people should have better oppor...   \n",
       "\n",
       "       person_text  \n",
       "0  Linda Cavanaugh  \n",
       "1         Sheriffs  \n",
       "2             JIBC  \n",
       "3             JIBC  \n",
       "4            Admin  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the documents with an entity label PERSON\n",
    "documents = []\n",
    "person_text = []\n",
    "raw_index = []\n",
    "\n",
    "for index, doc in enumerate(docs):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            raw_index.append(index)\n",
    "            documents.append(doc.text)\n",
    "            person_text.append(ent.text)          \n",
    "\n",
    "df_persons = pd.DataFrame({'original_index': raw_index,\n",
    "                           'documents': documents, \n",
    "                           'person_text': person_text})\n",
    "\n",
    "df_persons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example comment with sensitive information is printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The problem with the BCSS is Linda Cavanaugh and the CSB. Sheriffs are minimized and trivialized. The ADM has zero law enforcement experience. It is sickening how we are treated lumped in with civilian employees. Until sheriffs are removed from the CSB nothing will change. BCSS management has no ability to make changes because the ADM has her own civilian agenda. When will Government listen to us about how the CSB is killing us? ADM for years denied we had staffing  and wage issues when it was patently untrue. Why does the JIBC have ANY say into who we hire as instructors? JIBC is NOT a gov entity and should not have say on panels or appointing PTO's. JIBC is essentially a secret society. Only those who play their game get to teach there\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 893 words that have been identified with a `PERSON` tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(person_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORRECTING THE FALSE POSITIVES AND FALSE NEGATIVES**:  \n",
    "However there are several comments that NER incorrectly tagged as `PERSON`, and therefore they do not contain sensitive information. An example of this is the word \"Admin\", which is used quite often in the comments but is not a person. To adjust for this we have cross checked all of the sensitive persons with a database of ~90,000 names. There are also cases of false positives that are in the names list but are not sensitive. An example of this is \"Langford\" which NER has tagged, and it is in the names list. We have iteratively built a list of these names that shouldn't be in the names list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE list of names to cross reference \n",
    "\n",
    "df_names = pd.read_csv(\"../references/data-dictionaries/NationalNames.csv\")\n",
    "names = df_names.Name.unique().tolist()\n",
    "\n",
    "# Names that are in the names list and NER labels as Person, but are not actually\n",
    "# sensitive. ie. they are false positives\n",
    "false_names = ['Sheriff', 'Law', 'Child', 'Warden', 'Care', 'Cloud', 'Honesty',\n",
    "               'Maple', 'Marijuana', 'Parks', 'Ranger', 'Travel', 'Young', 'Branch',\n",
    "               'Field', 'Langford', 'Surrey', 'Cap', 'Lean', 'Van', 'Case', 'Min',\n",
    "               'Merit', 'Job', 'Win', 'Forest', 'Victoria']\n",
    "\n",
    "# Drop the false_names from the names list \n",
    "names = list(set(names).difference(set(false_names)))\n",
    "\n",
    "# Names that are not in the names list, but should be! ie. false negatives\n",
    "missing_names = ['Kristofferson']\n",
    "\n",
    "# Add missing names\n",
    "for missing_name in missing_names:\n",
    "    names.append(missing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross reference the \"persons\" with the name database\n",
    "sensitive_person = []\n",
    "person_index = []\n",
    "\n",
    "for index, person in enumerate(person_text):\n",
    "    for name in person.split(): \n",
    "        if name in names:\n",
    "            sensitive_person.append(person)\n",
    "            person_index.append(index)\n",
    "            break       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After accounting for words that are not actual names we have reduced the list of sensitive persons to 153."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sensitive_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at all of the `PERSON`s that we considered not to be sensitive based on the cross referencing the names data. We can see we correctly removed these `PERSON`s from the sensitive list. For printing below i have just shown 10 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adult',\n",
       " 'Happier',\n",
       " 'Service Level Agreements',\n",
       " 'Wardens',\n",
       " 'Teleworker',\n",
       " 'Sad',\n",
       " 'Limit',\n",
       " 'Kamloops',\n",
       " 'B.C.  ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(person_text).difference(set(sensitive_person)))[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can grab the index of the sensitive comments which can be used to remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_comment_indices = df_persons.original_index[person_index].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining comments that have not been identified as sensitive are tokenized as shown below and subsequently fed into the LSTM model at a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 12000\n",
    "maxlen = 700\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(np.array(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would suggest having a developmental growth plan within the Hiring Centre. For example: providing training for internal staff that are currently hiring clerks, to working with intake and then becoming a hiring advisor. I believe this would be an additional option for filing advisor vacancies, as admin staff would already have knowledge of all of the systems that we use internally and the hiring processes that we currently follow.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the above comment, you can see below that it is parsed as an array of unique numbers, each number representing a word. This array is what will be loaded on google collab to be used for our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,   11],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0, 1881],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0, 2725],\n",
       "       [   0,    0,    0, ...,    0,    0, 1881],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences(tokenizer.texts_to_sequences(comments[0]), maxlen=maxlen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
